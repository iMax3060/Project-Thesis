\chapter[Buffer Frame Free List]{Buffer Frame Free List} \label{ch:free-list}

\section[Purpose]{Purpose}

    Every disk-based DBMS requires some kind of buffer manager. A disk-based DBMS stores the pages of a database on secondary storage but to read and write pages, they are required to be in memory.

    This feature is provided by the buffer pool management by managing the currently used subset of the database pages in buffer frames located in memory. A buffer frame is a portion of memory that can hold one database page and each of those frames got a frame index as identifier.

    During operation, database pages are dynamically fetched from the database into buffer frames. Once a page is not required anymore, it might be evicted from the buffer pool freeing a buffer frame.

    Due to the fact that pages are only allowed to be fetched into free buffer frames, the buffer manager needs to know all the free buffer frames. Therefore, a free list for the buffer frames---storing the frame indexes of free buffer frames---is required.

\section[Compared Queue Implementations]{Compared Queue Implementations}

    To ease implementation of page eviction strategies like CLOCK, a free list should use a FIFO data structure like a queue. Therefore the buffer frame freed first is (re-)used first as well.

    Almost every state-of-the-art DBMS support multithreading and therefore, there are usually multiple threads concurrently fetching pages into the buffer pool and evicting pages from the buffer pool. Following this, a buffer frame free list has to support thread-safe functions to push frame indexes to the free list and to pop frame indexes from it. Queues providing those thread-safe access functions are usually called multi-producer (add frame indexes) multi-consumer (retrieve/remove frame indexes) queues (\textbf{MPMC} queues).

    An approximate number of buffer indexes in the free list must also be provided by any free list implementation to support the eviction of pages once there are only a few free buffer frames left. Thread-safe access to this number is desirable but not absolutely required.

\subsection[Boost Lock-Free Queue with variable size]{Boost Lock-Free Queue with variable size} \label{subsec:boost}

    The famous \textit{Boost C++ Libraries}\footnote{\url{https://www.boost.org/}} offer a lock-free unbounded MPMC queue\footnote{\url{https://www.boost.org/doc/libs/release/doc/html/boost/lockfree/queue.html}} in the library \lstinline{Boost.Lockfree}\footnote{\url{https://www.boost.org/doc/libs/release/doc/html/lockfree.html}}. Like many other non-blocking thread-safe data structures, this MPMC queue uses atomic operations instead of locks or mutexes. To support queues of dynamically changing sizes, this queue implementation also uses a free list for the dynamic memory management internally.

    This data structure does not offer the number of contained elements and therefore, an approximate number of buffer indexes in the free list needs to be managed outside.

\subsection[Boost Lock-Free Queue with fixed size]{Boost Lock-Free Queue with fixed size} \label{subsec:boost-fixed}

    This data structure is identical to the data structure in Subsection \ref{subsec:boost} but does not use dynamic memory management internally---it is a bounded queue. Therefore, the capacity of the queue (i.e. the maximum number of buffer frames of the buffer pool) needs to be specified beforehand which allows the usage of a fixed-size array instead of dynamically allocated nodes.

\subsection[CDS BasketQueue]{CDS Basket Lock-Free Queue} \label{subsec:cds-basket}

    Besides other concurrent data structures, the \textit{Concurrent Data Structures} C++ library\footnote{\url{https://github.com/khizmax/libcds}} offers many different thread-safe queue implementations. The unbounded \emph{Basket Lock-Free Queue}\footnote{\url{http://libcds.sourceforge.net/doc/cds-api/classcds\_1\_1container\_1\_1\_basket\_queue.html}} is based on the algorithm proposed by M. Hoffman, O. Shalev and N. Shavit in \cite{Hoffman:2007}.

    Internally, this queue does not use an absolute FIFO order. Instead, it puts concurrently enqueued elements into one ``basket'' of elements. The elements within one basket are not specifically ordered but the different ``baskets'' used over time are ordered according to FIFO. Therefore, the dequeue operation just dequeues one of the elements in the oldest ``basket''. The dynamic memory management uses a garbage collector to deallocate emptied ``baskets''.

\subsection[CDS FCQueue]{CDS Flat-Combining Lock-Free Queue} \label{subsec:cds-fc}

    The \textit{Concurrent Data Structures} C++ library does also offer an unbounded thread-safe queue that uses Flat Combining\footnote{\url{http://libcds.sourceforge.net/doc/cds-api/classcds\_1\_1container\_1\_1\_f\_c\_queue.html}}. The Flat Combining technique was proposed by D. Hendler, I. Incze, N. Shavit and M. Tzafrir in \cite{Hendler:2010}.  This technique is used to make any sequential data structure thread-safe---in case of the \emph{Flat-Combining Lock-Free Queue}, the \lstinline{std::queue}\footnote{\url{https://en.cppreference.com/w/cpp/container/queue}} of the \textit{C++ Standard Library}\footnote{\url{https://en.cppreference.com/w/cpp}} is used as base data structure.

    The Flat Combining technique uses thread-local publication lists to record operations performed by those threads. A global lock is needed to be acquired to combine these thread-local publication lists into the global, sequential data structure. The thread which acquired the global lock also combines the publication lists of all other threads reducing the locking overhead. The returned value of each operation executed during the combining is stored into the respective publication list together with the global combining pass number. A thread with a non-empty publication list that cannot acquire the global lock needs to wait till the combining thread updated its publication list.

\subsection[CDS MSQueue]{CDS Michael \& Scott Lock-Free Queue} \label{subsec:cds-ms}

    Another unbounded lock-free queue implementation offered by the \textit{Concurrent Data Structures} C++ library is based on the famous Michael \& Scott lock-free queue algorithm\footnote{\url{http://libcds.sourceforge.net/doc/cds-api/classcds\_1\_1container\_1\_1\_m\_s\_queue.html}} which was proposed by M. Michael and M. Scott in \cite{Michael:1996}.

    The Michael \& Scott lock-free queue basically uses compare-and-swap (\textbf{CAS}) operations on the tail of the queue to synchronize enqueue operations. If a thread reads a NULL value as next element after the queue's tail, it swaps this value atomically with the value enqueued by this thread. Afterwards it adjusts the tail pointer. If a thread does not read the NULL value there during the CAS operation, another thread has not already adjusted the tail pointer and this thread needs to retry its enqueue operation with the new tail pointer. The dequeue operation is implemented similarly. The memory occupied by already dequeued elements is deallocated using a garbage collector provided by the library.

\subsection[CDS MoirQueue]{CDS Variation of Michael \& Scott Lock-Free Queue} \label{subsec:cds-moir}

    The \textit{Concurrent Data Structures} C++ library also offers an optimized variation of the Michael \& Scott unbounded lock-free queue algorithm\footnote{\url{http://libcds.sourceforge.net/doc/cds-api/classcds\_1\_1container\_1\_1\_moir\_queue.html}} which is based on the works of S. Doherty, L. Groves, V. Luchangco and M. Moir in \cite{Doherty:2004}.

    This optimization of the Michael \& Scott lock-free queue optimizes the dequeue operation to only read the tail pointer once.

\subsection[CDS RWQueue]{CDS Michael \& Scott Blocking Queue with Fine-Grained Locking} \label{subsec:cds-rw}

    M. Michael and M. Scott did also propose a blocking queue algorithm in \cite{Michael:1996}. This unbounded blocking queue implementation\footnote{\url{http://libcds.sourceforge.net/doc/cds-api/classcds\_1\_1container\_1\_1\_r\_w\_queue.html}} is also offered by the \textit{Concurrent Data Structures} C++ library.

    This blocking queue algorithm uses one read and one write lock protecting the head and tail of the queue. Therefore, only one thread a time can enqueue and only one thread at a time can dequeue elements. The deallocation of memory during dequeuing is done by the dequeuing thread instead of relying on a garbage collector.

\subsection[CDS OptimisticQueue]{CDS Ladan-Mozes \& Shavit Optimistic Queue} \label{subsec:cds-optimistic}

    The \textit{Concurrent Data Structures} C++ library also offers an unbounded optimistic queue implementation\footnote{\url{http://libcds.sourceforge.net/doc/cds-api/classcds\_1\_1container\_1\_1\_optimistic\_queue.html}} which is based on an algorithm proposed by E. Ladan-Mozes and N. Shavit in \cite{Ladan-Mozes:2004}.

    Instead of using expensive CAS operations on a singly-linked list (like in the Michael \& Scott lock-free queue), this algorithm uses a doubly-linked list with the possibility to detect and fix inconsistent enqueue and dequeue operations. Deallocation of memory is done using a garbage collector.

\subsection[CDS SegmentedQueue]{CDS Segmented Queue} \label{subsec:cds-segmented}

    The unbounded segmented queue implementation\footnote{\url{http://libcds.sourceforge.net/doc/cds-api/classcds\_1\_1container\_1\_1\_segmented\_queue.html}} of the \textit{Concurrent Data Structures} C++ library is based on an algorithm proposed by Y. Afek, G. Korland and E. Yanovsky in \cite{Afek:2010}.

    This thread-safe queue algorithm is very similar to the basket lock-free queue. It also uses a relaxed FIFO order by ordering segments containing multiple elements instead of single elements. A thread enqueuing or dequeuing elements into the tail segment or from the head segment selects one of the slots inside the segment randomly. CAS operations are used to atomically enqueue or dequeue an element from a slot. If the CAS fails, another slot is taken randomly. The size of each segment---which can be selected ($8$ was used for the performance evaluation in Section \ref{sec:free-list-performance})---determines the relaxness of the FIFO order. Deallocation of emptied segments is done by a garbage collector.

\subsection[CDS VyukovMPMCCycleQueue]{CDS Vyukov's MPMC Bounded Queue} \label{subsec:cds-vyukovmpmccycle}

    The last thread-safe queue implementation\footnote{\url{http://libcds.sourceforge.net/doc/cds-api/classcds\_1\_1container\_1\_1\_vyukov\_m\_p\_m\_c\_cycle\_queue.html}} provided by the \textit{Concurrent Data Structures} C++ library is bounded and was developed by D. Vyukov\footnote{\url{http://www.1024cores.net/home/lock-free-algorithms/queues/bounded-mpmc-queue}}. The queue implementation in Subsection \ref{subsec:vyukov} is his original implementation.

    Vyukov's thread-safe queue implementation is very similar to Michael \& Scott blocking queue with fine-grained locking from Subsection \ref{subsec:cds-rw} but instead of using mutexes as locks, his implementation uses atomic read-modify-write (\textbf{RMW}) operations. This results in a cost of basically one CAS operation per enqueue/dequeue operation.

\subsection[Folly MPMC Queue]{Folly MPMC Queue} \label{subsec:folly-mpmc}

    Facebook's open source library \textit{Folly}\footnote{\url{https://github.com/facebook/folly}} provides a bounded lock-free queue implementation. An unbounded queue is also provided but due to the typically lower performance of unbounded queues, it is not evaluated in Section \ref{sec:free-list-performance}.

    \textit{Folly}'s MPMC queue uses a ticket dispenser system to give a thread access to one of the single-element queues used. Those ticket dispensers for the head and tail of the queue use atomic increment operations which are supposed to be more robust to contention than CAS operations used e.g. in the Michael \& Scott lock-free queue.

\subsection[Dmitry Vyukov's MPMC Queue]{Dmitry Vyukov's Bounded MPMC Queue} \label{subsec:vyukov}

    This\footnote{\url{http://www.1024cores.net/home/lock-free-algorithms/queues/bounded-mpmc-queue}} is Vyukov's original implementation of his bounded thread-safe MPMC queue.

\subsection[Gavin Lambert's MPMC Queue]{Gavin Lambert's MPMC Bounded Lock-Free Queue} \label{subsec:lampert}

    This\footnote{\url{https://gist.github.com/uecasm/b547db812ae4bba39bb1bd0443801507}} is another implementation of Vyukov's thread-safe queue made by [Gavin Lambert.

\subsection[\lstinline{moodycamel::ConcurrentQueue}]{\lstinline{moodycamel::ConcurrentQueue}} \label{subsec:moodycamel}

    This lock-free queue implementation\footnote{\url{https://github.com/cameron314/concurrentqueue}} is either unbounded or bounded depending on the used enqueuing functions and on the optional preallocation of memory (bounded behavior is used during the performance evaluation in Section \ref{sec:free-list-performance}). A blocking queue implementation provided by the same library is not evaluated in Section \ref{sec:free-list-performance} because it is just a wrapper around the non-blocking version adding additional overhead in low-contention workloads (like the free list).

    Internally, this queue implementation uses one SPMC (single producer/multiple consumer) queue per thread. Each thread enqueues elements only into its thread-local SPMC queue. When a thread tries to dequeue an element, it checks SPMC queues for emptiness until it finds one containing elements. It then dequeues one element from the SPMC queue. Therefore, this thread-safe queue does not maintain the order of elements enqueued by different threads.

    Due to the implementation using multiple SPMC queues, this queue implementation should only be used as a buffer frame free list when there is exactly one thread evicting pages from the buffer pool---and therefore, enqueuing buffer frame indexes of emptied buffer frames.

\subsection[Matt Stump's MPMC Queue]{Matt Stump's Bounded MPMC Queue} \label{subsec:vyukov-variation}

    This\footnote{\url{https://github.com/mstump/queues}} is another implementation of Vyukov's thread-safe queue made by Matt Stump.

\subsection[Erik Rigtorp's MPMC Queue]{Erik Rigtorp's Bounded MPMC Queue} \label{subsec:rigtorp}

    The bounded lock-free queue\footnote{\url{https://github.com/rigtorp/MPMCQueue}} of Erik Rigtorp uses a ticket dispenser system similar to the one of \textit{Folly}'s MPMC queue from Subsection \ref{subsec:folly-mpmc}.

\subsection[TBB Concurrent Queue]{Threading Building Blocks Concurrent Queue} \label{subsec:intel-bounded}%Check license

    The \textit{Threading Building Blocks} library\footnote{\url{https://www.threadingbuildingblocks.org/}} is an open source library originally developed by Intel®. The first thread-safe queue implementation\footnote{\url{https://software.intel.com/en-us/node/506200}} of this library is unbounded and non-blocking.

    Internally, this queue implementation uses multiple lock-based micro queues to allow concurrent enqueue/dequeue executions. Therefore, the guarantees of this queue is similar to those of the \lstinline{moodycamel::ConcurrentQueue} from Subsection \ref{subsec:moodycamel}.

\subsection[TBB Bounded Concurrent Queue]{Threading Building Blocks Bounded Concurrent Dual Queue} \label{subsec:intel-unbounded}%Check license

    The other thread-safe queue implementation\footnote{\url{https://software.intel.com/en-us/node/506201}} of the \textit{Threading Building Blocks} library is unbounded and partially non-blocking.

    This queue implementation is almost identical to the other one of the Threading Building Blocks library but it does allow the limitation of the capacity. An enqueuing operation has to wait if the queue is already full according to the specified capacity.

\section[Performance Evaluation]{Performance Evaluation} \label{sec:free-list-performance}

\subsection[Micro Benchmark]{Micro Benchmark}

    The used micro benchmark simulates a high contented free list. The number of working threads, the number of iterations (either the fetching of a page into a free buffer frame or the eviction of a batch of pages) per thread and the batch size of buffer frames to be freed at once can be varied. It does not simulate a complete buffer pool---there is only the free list with operations to enqueue and dequeue buffer frame indexes. Each working thread performs the following operations per iterations:

\begin{@empty}
    \begin{itemize}
        \itemsep0em
        \item If the free list is not empty:
        \begin{itemize}
            \item Retrieve a buffer frame index from the free list.
            \item Mark the retrieved buffer frame used.
        \end{itemize}
        \item If the free list is empty:
        \begin{itemize}
            \item While the free list is smaller than the batch eviction size:
            \begin{itemize}
                \item Select a random buffer frame index using a fast random numbers generator.
                \item If this buffer frame index is marked used:
                \begin{itemize}
                    \item Mark the selected buffer frame index unused.
                    \item Add the selected buffer frame index to the free list.
                \end{itemize}
            \end{itemize}
        \end{itemize}
    \end{itemize}
\end{@empty}

\subsection[Queue Versions]{Used Versions of the Libraries and Queue Implementations}

\begin{@empty}
    \begin{itemize}
        \itemsep0em
        \item \textit{Boost C++ Libraries} 1.58
        \item \textit{Concurrent Data Structures} C++ library 2.3.3\footnote{\url{https://github.com/khizmax/libcds/tree/5fc87a172bd82f8a7040b8b83f32ce0e635e82ea}}
        \item \textit{Folly} \lstinline{a15fcb1e76}\footnote{\url{https://github.com/facebook/folly/tree/a15fcb1e76444f7d464b263ad37bf3b5fbfdf33e}}
        \item Dmitry Vyukov's Original MPMC Queue as of September 2017
        \item Gavin Lambert's MPMC Queue as of September 2017\footnote{\url{https://gist.github.com/uecasm/b547db812ae4bba39bb1bd0443801507/e40906811cb14118d328c353250559fe359f3ba7}}
        \item \lstinline{moodycamel::ConcurrentQueue} \lstinline{9f9c4e0cf4}\footnote{\url{https://github.com/cameron314/concurrentqueue/tree/9f9c4e0cf400bcc5c27a041e524f04e950736b25}}
        \item Matt Stump's MPMC Queue \lstinline{319c253d68}\footnote{\url{https://github.com/mstump/queues/tree/319c253d68f14ac9593c3727d1597a87af73c99b}}
        \item Erik Rigtorp's MPMC Queue \lstinline{57366e41f3}\footnote{\url{https://github.com/rigtorp/MPMCQueue/tree/57366e41f3f48316f175c2e704795f519a92e1d5}}
        \item Intel® Threading Building Blocks 2017 Update 7
    \end{itemize}
\end{@empty}

\subsection[System Configuration]{Configuration of the Used System}

\begin{@empty}
    \begin{itemize}
        \itemsep0em
        \item \textbf{CPU:} $2 \times $ \emph{Intel® Xeon® Processor X5670} @$6 \times 2.93\text{GHz}$ released early 2010
        \item \textbf{Main Memory:} $12 \times 8\text{GB} = 96\text{GB}$ of DDR2-SDRAM @$1333\text{MHz}$
        \item \textbf{OS:} \emph{Ubuntu 16.04}
    \end{itemize}
\end{@empty}

\section{Conclusion}
