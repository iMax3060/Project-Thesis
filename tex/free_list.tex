\chapter[Buffer Frame Free List]{Buffer Frame Free List} \label{ch:free-list}

\section[Purpose]{Purpose}

	When not relying on the unsuitable VM management of the OS---every disk-based DBMS requires some kind of buffer manager which provides in-memory copies of database pages---which are stored persistently on secondary storage---to the upper layers of the DBMS for processing.
	
	This feature is provided by the buffer pool management by managing the currently used subset of the database pages---the working set---in buffer frames located in memory. In the common case of fixed-size pages, a buffer frame is a portion of memory that can hold one database page and each of those frames has a frame index as identifier.
	
	During operation, database pages are dynamically fetched from the database into buffer frames. Once a page's availability in memory is not required anymore (i.e. it is not required for the processing of any current transaction), it might be evicted from the buffer pool freeing a buffer frame.
	
	The buffer manager needs some kind of free list when it allocates a buffer frame to a fetched database page because unrestricted overwriting of data in buffer frames would cause undefined behavior.

\section[Compared Open Source Queue Implementations]{Compared Open Source Queue Implementations}

	To ease implementation of page eviction strategies like CLOCK, a free list should use a FIFO data structure like a queue---typically implemented as linked list. Therefore, the buffer frame freed first is (re-)used first as well.
	
	Almost every state-of-the-art DBMS supports multi-threading and therefore, there are usually multiple threads concurrently fetching pages into the buffer pool and evicting pages from the buffer pool. Following this, a buffer frame free list has to support thread-safe functions to push frame indexes to the free list and to pop frame indexes from it. Queues providing those thread-safe access functions are usually called multi-producer (add frame indexes) multi-consumer (retrieve/remove frame indexes) queues (\textbf{MPMC} queues).
	
	An approximate number of buffer indexes in the free list should also be provided by any free list implementation to support the (batch-wise) eviction of pages once there are only a few free buffer frames left. Thread-safe access to this number is desirable but not absolutely required.

\subsection[Boost Lock-Free Queue with Variable Size]{Boost Lock-Free Queue with Variable Size} \label{subsec:boost}

	The popular \textit{Boost C++ Libraries}\footnote{\url{https://www.boost.org/}} offer a \textbf{lock-free} \textbf{unbounded} MPMC queue\footnote{\url{https://bit.ly/2Q9w45H}} in the library \texttt{Boost.Lockfree}\footnote{\url{https://bit.ly/2FiPyip}}.

    Like many other \textbf{non-blocking} thread-safe data structures, this MPMC queue uses atomic operations instead of locks or mutexes. To support dynamic growing and shrinking of the queue, this queue implementation also uses a free list for its own internal dynamic memory management.
	
	This data structure does not offer the number of contained elements and therefore, an approximate number of buffer indexes in the free list needs to be managed externally.

\subsection[Boost Lock-Free Queue with Fixed Size]{Boost Lock-Free Queue with Fixed Size} \label{subsec:boost-fixed}

	This queue implementation is identical to the data structure in Subsection \ref{subsec:boost} but does not use dynamic memory management internally---it is a \textbf{bounded} queue. As long as the needed capacity of the queue---in our case the maximum number of buffer frames in the buffer pool---is known when the queue is allocated, this queue implementation can be used. This implementation uses a fixed-size array instead of dynamically allocated nodes for its stored data---the indexes of free buffer frames.

\subsection[CDS BasketQueue]{CDS Basket Lock-Free Queue} \label{subsec:cds-basket}

	Besides many other concurrent data structures, the \textit{Concurrent Data Structures} C++ library\footnote{\url{https://github.com/khizmax/libcds}} offers many different thread-safe queue implementations. The \textbf{unbounded} \emph{basket lock-free queue}\footnote{\url{https://bit.ly/2SGv2A6}} is based on the algorithm proposed by M. Hoffman, O. Shalev and N. Shavit in \cite{Hoffman:2007}.
	
	Internally, this queue does not use an absolute FIFO order. Instead, it puts concurrently enqueued elements into one ``basket'' of elements. The elements within one basket are not specifically ordered but the different ``baskets'' used over time are ordered according to FIFO. Therefore, the dequeue operation just dequeues one of the elements in the oldest ``basket''. The dynamic memory management uses a garbage collector to deallocate emptied ``baskets''.

\subsection[CDS FCQueue]{CDS Flat-Combining Sequential Queue} \label{subsec:cds-fc}

	The \textit{Concurrent Data Structures} C++ library does also offer an \textbf{unbounded} thread-safe queue that uses flat combining\footnote{\url{https://bit.ly/2ZEsrYO}}. The flat combining technique was proposed by D. Hendler, I. Incze, N. Shavit and M. Tzafrir in \cite{Hendler:2010}.  This technique can make any sequential data structure thread-safe---in case of the \emph{flat-combining sequential queue}, the \texttt{std::queue}\footnote{\url{https://en.cppreference.com/w/cpp/container/queue}} of the \textit{C++ Standard Library}\footnote{\url{https://en.cppreference.com/w/cpp}} is used as base data structure.
	
	The flat combining technique uses thread-local publication lists to record operations performed by those threads. A \textbf{global lock} is needed to be acquired to combine these thread-local publication lists into the global, sequential data structure. The thread which acquired the global lock also combines the publication lists of all other threads reducing the locking overhead. The returned value of each operation executed during the combining is stored into the respective publication list together with the global combining pass number. A thread with a non-empty publication list that cannot acquire the global lock needs to wait till the combining thread updated its publication list.

\subsection[CDS MSQueue]{CDS Michael \& Scott Lock-Free Queue} \label{subsec:cds-ms}

	Another \textbf{unbounded} \textbf{lock-free} queue implementation offered by the \textit{Concurrent Data Structures} C++ library is based on the famous Michael \& Scott lock-free queue algorithm\footnote{\url{https://bit.ly/37onMwC}}, proposed by M. Michael and M. Scott in \cite{Michael:1996}.
	
	The Michael \& Scott lock-free queue basically uses compare-and-swap (\textbf{CAS}) operations on the tail of the queue to synchronize enqueue operations. If a thread reads a \texttt{NULL} value as next element after the queue's tail, it swaps this value atomically with the value enqueued by this thread. Afterwards it adjusts the tail pointer. If a thread does not read the \texttt{NULL} value there during the CAS operation, another thread has not already adjusted the tail pointer and this thread needs to retry its enqueue operation with the new tail pointer. The dequeue operation is implemented similarly. The memory occupied by already dequeued elements is deallocated using a garbage collector provided by the library.

\subsection[CDS MoirQueue]{CDS Variation of Michael \& Scott Lock-Free Queue} \label{subsec:cds-moir}

	The \textit{Concurrent Data Structures} C++ library also offers an optimized variation of the Michael \& Scott \textbf{unbounded} \textbf{lock-free} queue algorithm\footnote{\url{https://bit.ly/2MG8dbM}} which is based on the works of S. Doherty, L. Groves, V. Luchangco and M. Moir in \cite{Doherty:2004}.
	
	This optimization of the Michael \& Scott lock-free queue optimizes the dequeue operation to only read the tail pointer once.

\subsection[CDS RWQueue]{CDS Michael \& Scott Blocking Queue with Fine-Grained Locking} \label{subsec:cds-rw}

	M. Michael and M. Scott did also propose a blocking queue algorithm in \cite{Michael:1996}. This \textbf{unbounded} \textbf{blocking} queue implementation\footnote{\url{https://bit.ly/2SCeFo5}} is also offered by the \textit{Concurrent Data Structures} C++ library.
	
	This blocking queue algorithm uses one read and one write lock protecting the head and tail of the queue. Therefore, only one thread a time can enqueue and only one thread at a time can dequeue elements. The deallocation of memory during dequeuing is done by the dequeuing thread instead of relying on a garbage collector.

\subsection[CDS OptimisticQueue]{CDS Ladan-Mozes \& Shavit Optimistic Queue} \label{subsec:cds-optimistic}

	The \textit{Concurrent Data Structures} C++ library also offers an \textbf{unbounded} \textbf{optimistic} queue implementation\footnote{\url{https://bit.ly/37mgQQM}} which is based on an algorithm proposed by E. Ladan-Mozes and N. Shavit in \cite{Ladan-Mozes:2004}.
	
	Instead of using expensive CAS operations on a singly-linked list (like in the Michael \& Scott lock-free queue), this algorithm uses a doubly-linked list with the possibility to detect and fix inconsistent enqueue and dequeue operations. Deallocation of memory is done using a garbage collector.

\subsection[CDS SegmentedQueue]{CDS Segmented Queue} \label{subsec:cds-segmented}

	The \textbf{unbounded} segmented queue implementation\footnote{\url{https://bit.ly/37mjXYR}} of the \textit{Concurrent Data Structures} C++ library is based on an algorithm proposed by Y. Afek, G. Korland and E. Yanovsky in \cite{Afek:2010}.
	
	This thread-safe queue algorithm is very similar to the basket lock-free queue from Subsection \ref{subsec:cds-basket}. It also uses a relaxed FIFO order by ordering segments containing multiple elements instead of single elements. A thread enqueuing or dequeuing elements into the tail segment or from the head segment selects one of the slots inside the segment randomly. CAS operations are used to atomically enqueue or dequeue an element from a slot. If the CAS fails, another slot is taken randomly. The size of each segment---which can be selected ($8$ was used for the performance evaluation in Section \ref{sec:free-list-performance})---determines the relaxness of the FIFO order. Deallocation of emptied segments is done by a garbage collector.

\subsection[CDS VyukovMPMCCycleQueue]{CDS Vyukov's MPMC Bounded Queue} \label{subsec:cds-vyukovmpmccycle}

	The last thread-safe queue implementation\footnote{\url{https://bit.ly/2ML9Y7M}} provided by the \textit{Concurrent Data Structures} C++ library is \textbf{bounded} and was developed by D. Vyukov\footnote{\url{https://bit.ly/39n4PMF}}. The queue in Subsection \ref{subsec:vyukov} is his original implementation.

\subsection[Folly MPMC Queue]{Folly MPMC Queue} \label{subsec:folly-mpmc}

	Facebook's open source library \textit{Folly}\footnote{\url{https://github.com/facebook/folly}} provides a \textbf{bounded} \textbf{lock-free} queue implementation. An unbounded version is also provided but due to the typically higher performance of bounded ones, it is not evaluated here.
	
	\textit{Folly}'s MPMC queue uses a ticket dispenser system to give a thread access to one of the single-element queues used. Those ticket dispensers for the head and tail of the queue use atomic increment operations which are supposed to be more robust to contention than CAS operations used e.g. in the Michael \& Scott lock-free queue.

\subsection[Dmitry Vyukov's MPMC Queue]{Dmitry Vyukov's Bounded MPMC Queue} \label{subsec:vyukov}

	This\footnote{\url{https://bit.ly/35a5lKL}} is Vyukov's original implementation of his \textbf{bounded} thread-safe MPMC queue.

	Vyukov's thread-safe queue implementation is very similar to Michael \& Scott blocking queue with fine-grained locking from Subsection \ref{subsec:cds-rw} but instead of using mutexes as locks, his implementation uses atomic read-modify-write (\textbf{RMW}) operations. This results in a cost of basically one CAS operation per enqueue/dequeue operation.

\subsection[Gavin Lambert's MPMC Queue]{Gavin Lambert's MPMC Bounded Lock-Free Queue} \label{subsec:lampert}

	This\footnote{\url{https://bit.ly/2F7jvlb}} is another version of Vyukov's thread-safe queue design from Subsection \ref{subsec:vyukov} implemented by Gavin Lambert.

%\subsection[\texttt{moodycamel::ConcurrentQueue}]{\texttt{moodycamel::ConcurrentQueue}} \label{subsec:moodycamel}
%
%	This \textbf{lock-free} queue implementation\footnote{\url{https://github.com/cameron314/concurrentqueue}} is either \textbf{unbounded or bounded} depending on the used enqueuing functions and on the optional preallocation of memory (bounded behavior is used during the performance evaluation in Section \ref{sec:free-list-performance}). A blocking queue implementation provided by the same library is not evaluated in Section \ref{sec:free-list-performance} because it is just a wrapper around the non-blocking version adding additional overhead in low-contention workloads (like the free list).
%	
%	Internally, this queue implementation uses one SPMC (single producer/multiple consumer) queue per thread. Each thread enqueues elements only into its thread-local SPMC queue. When a thread tries to dequeue an element, it checks SPMC queues for emptiness until it finds one containing elements. It then dequeues one element from the SPMC queue. Therefore, this thread-safe queue does not maintain the order of elements enqueued by different threads.
%	
%	Due to the implementation using multiple SPMC queues, this queue implementation should only be used as a buffer frame free list when there is exactly one thread evicting pages from the buffer pool---and therefore, enqueuing buffer frame indexes of emptied buffer frames.
%
\subsection[Matt Stump's MPMC Queue]{Matt Stump's Bounded MPMC Queue} \label{subsec:vyukov-variation}

	This\footnote{\url{https://github.com/mstump/queues}} is another version of Vyukov's thread-safe queue design from Subsection \ref{subsec:vyukov} implemented by Matt Stump.

\subsection[Erik Rigtorp's MPMC Queue]{Erik Rigtorp's Bounded MPMC Queue} \label{subsec:rigtorp}

	The \textbf{bounded} \textbf{lock-free} queue\footnote{\url{https://github.com/rigtorp/MPMCQueue}} of Erik Rigtorp uses a ticket dispenser system similar to the one of \textit{Folly}'s MPMC queue from Subsection \ref{subsec:folly-mpmc}.

\subsection[TBB Concurrent Queue]{TBB Concurrent Queue} \label{subsec:intel-unbounded}

	The \textit{Threading Building Blocks} library\footnote{\url{https://www.threadingbuildingblocks.org/}} is an open source library originally developed by Intel®. The first thread-safe queue implementation\footnote{\url{https://software.intel.com/en-us/node/506200}} of this library is \textbf{unbounded} and \textbf{non-blocking}.
	
	Internally, this queue implementation uses multiple lock-based micro queues to allow concurrent enqueue/dequeue executions. Therefore, this thread-safe queue does not maintain the order of elements enqueued by different threads.

    Due to the implementation using multiple SPMC queues, this queue implementation should only be used as a buffer frame free list when there is exactly one thread evicting pages from the buffer pool---and therefore, enqueuing buffer frame indexes of emptied buffer frames.

\subsection[TBB Bounded Concurrent Queue]{TBB Bounded Concurrent Dual Queue} \label{subsec:intel-bounded}

	The other thread-safe queue implementation\footnote{\url{https://software.intel.com/en-us/node/506201}} of the \textit{Threading Building Blocks} library is \textbf{bounded} and \textbf{partially non-blocking}.
	
	This queue implementation is almost identical to the other one of the \textit{Threading Building Blocks} library but it does allow the limitation of the capacity. An enqueuing operation has to wait if the queue is already full according to the specified capacity.

\section[Performance Evaluation]{Performance Evaluation} \label{sec:free-list-performance}

\subsection[Microbenchmark]{Microbenchmark} \label{subsec:free-list-microbenchmark}

	The used microbenchmark simulates a high contented free list. The number of working threads, the number of iterations (either the fetching of a page into a free buffer frame or the eviction of a batch of pages) per thread and the batch size of buffer frames to be freed at once can be varied. It does not simulate a complete buffer pool---there is only the free list with operations to enqueue and dequeue buffer frame indexes. Each working thread performs the following operations per iterations:
	
\begin{@empty}
	\begin{itemize}
		\itemsep0em
		\item If the free list is not empty:
			\begin{itemize}
				\item Retrieve a buffer frame index from the free list.
				\item Mark the retrieved buffer frame used.
			\end{itemize}
		\item If the free list is empty:
			\begin{itemize}
				\item While the free list is smaller than the batch eviction size:
					\begin{itemize}
						\item Select a random buffer frame index using a fast random numbers generator.
						\item If this buffer frame index is marked used:
							\begin{itemize}
								\item Mark the selected buffer frame index unused.
								\item Add the selected buffer frame index to the free list.
							\end{itemize}
					\end{itemize}
			\end{itemize}
	\end{itemize}
\end{@empty}

\subsection[Queue Versions]{Used Versions of the Libraries and Queue Implementations} \label{subsec:free-list-versions}

\begin{@empty}
	\begin{itemize}
		\itemsep0em
		\item	\textit{Boost C++ Libraries} 1.67
		\item	\textit{Concurrent Data Structures} C++ library 2.3.1\footnote{\url{https://bit.ly/39vysvB}}
		\item	\textit{Folly} \texttt{a8d1fd8}\footnote{\url{https://bit.ly/2sy4J4l}}
		\item	Dmitry Vyukov's Bounded MPMC Queue as of September 2017\footnote{\url{https://bit.ly/2MHbXtG}}
		\item	Gavin Lambert's MPMC Bounded Lock-Free Queue \texttt{e409068}\footnote{\url{https://bit.ly/2sy6QoN}}
%		\item	\texttt{moodycamel::ConcurrentQueue} \texttt{ffda5a4}\footnote{\url{https://bit.ly/2sqDpVM}}
		\item	Matt Stump's MPMC Queue \texttt{319c253}\footnote{\url{https://bit.ly/2ZBEMgk}}
		\item	Erik Rigtorp's MPMC Queue \texttt{553cf42}\footnote{\url{https://bit.ly/2F7cH7d}}
		\item	Intel® Threading Building Blocks 2019 Update 9
	\end{itemize}
\end{@empty}

\subsection[System Configuration]{Configuration of the Used System} \label{subsec:free-list-system-configuration}

\begin{@empty}
	\begin{itemize}
		\itemsep0em
		\item	\textbf{CPU:} \emph{Intel® Core™ i7-8700} @$12 \times \SI{3.2}{\giga\hertz}$ from late 2017
		\item	\textbf{Main Memory:} $2 \times 8\text{GB} = 16\text{GB}$ of DDR4-SDRAM @\SI{2666}{\mega\hertz}
		\item	\textbf{OS:} \emph{Ubuntu 19.10}
	\end{itemize}
\end{@empty}

\subsection[Microbenchmark Results]{Microbenchmark Results} \label{subsec:free-list-results}

\begin{@empty}
    Figure \ref{fig:free_list_performance} shows the free list operation throughput measured with the microbenchmark. Each iteration of the microbenchmark from Subsection \ref{subsec:free-list-microbenchmark}---performing either a pull or a push operation on the free list---is one operation on the evaluated free list queue. The operation throughput is total number of operations (from all working threads) performed on the free list per time.
        
	\nottoggle{bwmode}{
        \tikzset{%
            boostLockFreeVariable/.style = {color = simpleMaroon, mark = *},
            boostLockFreeFixed/.style = {color = simpleBrown, mark = square*},
            CDSBasketQueue/.style = {color = simpleOlive, mark = triangle*},
            CDSFCQueue/.style = {color = simpleTeal, mark = diamond*},
            CDSMoirQueue/.style = {color = simpleNavy, mark = *},
            CDSMSQueue/.style = {color = simpleBlack, mark = square*},
            CDSOptimisticQueue/.style = {color = simpleRed, mark = triangle*},
            CDSRWQueue/.style = {color = simpleOrange, mark = diamond*},
            CDSSegmentedQueue/.style = {color = simpleLime, mark = *},
            CDSVyukovQueue/.style = {color = simpleGreen, mark = square*},
            FollyMPMCQueue/.style = {color = simpleCyan, mark = triangle*},
            DmitryVyukovMPMC/.style = {color = simpleBlue, mark = diamond*},
            GavinLampertMPMC/.style = {color = simplePurple, mark = *},
            MattStumpMPMC/.style = {color = simpleMagenta, mark = square*},
            RigtorpMPMC/.style = {color = simpleGrey, mark = triangle*},
            TBBUnbounded/.style = {color = simplePink, mark = diamond*},
            TBBBounded/.style = {color = simpleLavender, mark = *}
        }
    }{
        \tikzset{%
            boostLockFreeVariable/.style = {color = black!50, mark = diamond},
            boostLockFreeFixed/.style = {color = black!50, mark = x},
            CDSBasketQueue/.style = {color = black!50, mark = +},
            CDSFCQueue/.style = {color = black!50, mark = -},
            CDSMoirQueue/.style = {color = black!50, mark = |},
            CDSMSQueue/.style = {color = black!50, mark = o},
            CDSOptimisticQueue/.style = {color = black!50, mark = 10-pointed star},
            CDSRWQueue/.style = {color = black!50, mark = square},
            CDSSegmentedQueue/.style = {color = black!50, mark = triangle},
            CDSVyukovQueue/.style = {color = black, mark = x},
            FollyMPMCQueue/.style = {color = black, mark = +},
            DmitryVyukovMPMC/.style = {color = black, mark = o},
            GavinLampertMPMC/.style = {color = black, mark = 10-pointed star},
            MattStumpMPMC/.style = {color = black, mark = square},
            RigtorpMPMC/.style = {color = black, mark = triangle},
            TBBUnbounded/.style = {color = black, mark = diamond},
            TBBBounded/.style = {color = black, mark = |}
        }
    }

    \begin{figure}[ht!]
        \centering
        \resizebox{\textwidth}{!}{
            \begin{tikzpicture}[]
                \begin{axis}[xlabel = {Number of threads},
                             xlabel near ticks,
                             xmin = 1,
                             xmax = 12,
                             xtick distance = 3,
                             extra x ticks = {1},
                             scaled x ticks = false,
                             ylabel = {$\text{Average free list operation throughput }\left[\si{\operations\per\second}\right]$},
                             ylabel near ticks,
                             ymode = log,
                             scaled y ticks = false,
                             grid = both,
                             width = \textwidth,
                             height = .65\textheight]

                    \addplot[boostLockFreeVariable] table[x = threads, y = throughput] {./data/free_list/boost_lockfree_queue.csv};                    \label{pgfplots:boost}
                    \addplot[boostLockFreeFixed]    table[x = threads, y = throughput] {./data/free_list/boost_lockfree_queue_fixed_size.csv};         \label{pgfplots:boost-fixed}
                    \addplot[CDSBasketQueue]        table[x = threads, y = throughput] {./data/free_list/cds_container_basketqueue.csv};               \label{pgfplots:cds-basket}
                    \addplot[CDSFCQueue]            table[x = threads, y = throughput] {./data/free_list/cds_container_fcqueue.csv};                   \label{pgfplots:cds-fc}
                    \addplot[CDSMoirQueue]          table[x = threads, y = throughput] {./data/free_list/cds_container_moirqueue.csv};                 \label{pgfplots:cds-moir}
                    \addplot[CDSMSQueue]            table[x = threads, y = throughput] {./data/free_list/cds_container_msqueue.csv};                   \label{pgfplots:cds-ms}
                    \addplot[CDSOptimisticQueue]    table[x = threads, y = throughput] {./data/free_list/cds_container_optimisticqueue.csv};           \label{pgfplots:cds-optimistic}
                    \addplot[CDSRWQueue]            table[x = threads, y = throughput] {./data/free_list/cds_container_rwqueue.csv};                   \label{pgfplots:cds-rw}
                    \addplot[CDSSegmentedQueue]     table[x = threads, y = throughput] {./data/free_list/cds_container_segmentedqueue.csv};            \label{pgfplots:cds-segmented}
                    \addplot[CDSVyukovQueue]        table[x = threads, y = throughput] {./data/free_list/cds_container_vyukovmpmccyclequeue.csv};      \label{pgfplots:cds-vyukovmpmccycle}
                    \addplot[FollyMPMCQueue]        table[x = threads, y = throughput] {./data/free_list/folly_mpmcqueue.csv};                         \label{pgfplots:folly-mpmc}
                    \addplot[DmitryVyukovMPMC]      table[x = threads, y = throughput] {./data/free_list/mpmc_bounded_queue.csv};                      \label{pgfplots:vyukov}
                    \addplot[GavinLampertMPMC]      table[x = threads, y = throughput] {./data/free_list/lockfree_queue_mpmc_fixed_bounded_value.csv}; \label{pgfplots:lampert}
                    \addplot[MattStumpMPMC]         table[x = threads, y = throughput] {./data/free_list/mpmc_bounded_queue_t.csv};                    \label{pgfplots:vyukov-variation}
                    \addplot[RigtorpMPMC]           table[x = threads, y = throughput] {./data/free_list/rigtorp_mpmcqueue.csv};                       \label{pgfplots:rigtorp}
                    \addplot[TBBUnbounded]          table[x = threads, y = throughput] {./data/free_list/tbb_concurrent_queue.csv};                    \label{pgfplots:intel-unbounded}
                    \addplot[TBBBounded]            table[x = threads, y = throughput] {./data/free_list/tbb_concurrent_bounded_queue.csv};            \label{pgfplots:intel-bounded}
                \end{axis}
            \end{tikzpicture}
        }
        \caption{The operation throughput of the evaluated free list queue implementations}
        \label{fig:free_list_performance}
    \end{figure}

    The \emph{CDS segmented queue} \ref{pgfplots:cds-segmented} is the slowest free list queue implementation for any number of concurrently working threads. The very similar \emph{CDS basket lock-free queue} \ref{pgfplots:cds-basket} performs as bad on 1 working thread and not much better on a higher number of threads.

    The \emph{CDS} queue implementations \emph{CDS Ladan-Mozes \& Shavit optimistic queue} \ref{pgfplots:cds-optimistic}, \emph{CDS Michael \& Scott lock-free queue} \ref{pgfplots:cds-ms} and \emph{CDS variation of Michael \& Scott lock-free queue} \ref{pgfplots:cds-moir} are also similar to each other and therefore, they all perform very similarly. Their performance for a low number of working threads is better than the one of the \emph{CDS Basket Lock-Free Queue} but for higher numbers of threads they perform even worse.

    The very simple \emph{CDS flat-combining lock-free queue} \ref{pgfplots:cds-fc} performs not too bad for $\leq 2$ threads but the global lock limits the concurrency and therefore, the performance falls by a factor of $>3$ when there are $\geq6$ threads concurrently working on the free list queue.

    The throughput of the two queue implementations from the \textit{Boost C++ Libraries}---the \emph{Boost lock-free queue with variable size} \ref{pgfplots:boost} and the \emph{Boost lock-free queue with fixed size} \ref{pgfplots:boost-fixed}---drops even earlier than the one of the \emph{CDS flat-combining lock-free queue}. For one working thread, they perform good but for $>1$ threads, their performance is bad. The overhead due to the dynamic memory management of the unbounded version is negligible.

    The three implementations of Vyukov's MPMC queue design---\emph{CDS Vyukov's MPMC bounded queue} \ref{pgfplots:cds-vyukovmpmccycle}, \emph{Matt Stump's bounded MPMC queue} \ref{pgfplots:vyukov-variation} and \emph{Gavin Lambert's MPMC bounded lock-free queue} \ref{pgfplots:lampert}---perform better than the ones mentioned already but the original \emph{Dmitry Vyukov's bounded MPMC queue} \ref{pgfplots:vyukov} performs even better. All the implementations of Vyukov's MPMC queue design are the best free list queues when there is only one working thread.

    The two queue implementations which use a ticket dispenser system for synchronization---the \emph{Folly MPMC queue} \ref{pgfplots:folly-mpmc} and \emph{Erik Rigtorp's bounded MPMC queue} \ref{pgfplots:rigtorp}---perform as good as Vyukov's MPMC queue design.

    The \emph{CDS Michael \& Scott blocking queue with fine-grained locking} \ref{pgfplots:cds-rw} and \emph{TBB bounded concurrent dual queue} \ref{pgfplots:intel-bounded} perform very similar as well.

    The best free list queue for $>2$ threads concurrently operating on the free list is the \emph{TBB concurrent queue} \ref{pgfplots:intel-unbounded}.
\end{@empty}

\section{Conclusion}

    The performance of the buffer pool free list is typically not critical for the overall performance of a DBMS---even a bad free list queue is unlikely to become the bottleneck of a DBMS. The buffer pool free list is mostly called when a database page is retrieved from secondary storage which is---even on an enterprise SSD---a very expensive operation.

    Depending on the further developments in NVRAM technology, memory devices of this class might not be able to completely replace DRAM in database applications in the near future, but they might replace---and already do so---existing secondary storage technologies like SSDs. According to specifications from \cite{Arulraj:2015}, the limiting factor---at least in OLTP applications---will be the endurance of the memory cells---which is basically the number of write operations per memory cell until it is worn out.

    Following these general assumptions, high contention on the buffer pool free list is very unlikely and therefore, the usage of \emph{Dmitry Vyukov's bounded MPMC queue} as buffer pool free list implementation can be recommended. But due to the superiority of the \emph{TBB concurrent queue} during contention on the free list, the low drawback during non-concurrent operation and the maturity of the library, this queue implementation can also be recommended.
